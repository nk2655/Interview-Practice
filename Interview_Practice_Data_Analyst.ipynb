{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Practice Data Analyst\n",
    "by NK Zhehua Zou\n",
    "\n",
    "*** Project: Answer the Following Interview Questions (6 total) ***  \n",
    "For each of the questions below, answer as if you were in an interview, explaining and justifying your answer with two to three paragraphs as you see fit. For coding answers, explain the relevant choices you made writing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Describe a data project you worked on recently.\n",
    "I used Python to analyze the survival percentage of Titanic passengers. The first step, I retrieved id in the dataset, found unnecessarily id and dropped them by pandas. But I found almost half of passengers missing age value in next step. There have two options I can take, drop missing values or fill them with mean value group by sex and pclass. After tested both of solutions, I picked drop missing values as a final decision, it looks like a better way for data visualization. The last step, I used plt and seaborn to visualize data for display count and correlation of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - You are given a ten piece box of chocolate truffles.\n",
    "You know based on the label that six of the pieces have an orange cream filling and four of the pieces have a coconut filling.  \n",
    "If you were to eat four pieces in a row, what is the probability that the first two pieces you eat have an orange cream filling and the last two have a coconut filling?\n",
    "Follow-up question: If you were given an identical box of chocolates and again eat four pieces in a row, what is the probability that exactly two contain coconut filling?  \n",
    "*** Answers ***  \n",
    "1) p = target / total  \n",
    "1st pick = 6/10, 2nd pick = 5/9, 3rd pick = 4/8, 4th pick = 3/7  \n",
    "final_p = 6/10 * 5/9 * 4/8 * 3/7 = 0.07143  \n",
    "  \n",
    "2) p = number of target combination / number of total combination\n",
    "number of combination with 1 orange (or 3 cocconuts) = 4  \n",
    "number of combination with 1 cocconut (or 3 oranges) = 4  \n",
    "number of combination with 2 oranges (or 2 cocconuts) = 6, [oocc, ccoo, cooc, occo, ococ, coco]  \n",
    "numer of combination with 4 oranges or 4 cocconuts = 2  \n",
    "final_p = 6/16 = 0.375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Given the table users:\n",
    "  \n",
    "##### Table \"users\"  \n",
    "| Column | Type |  \n",
    "|---|---|  \n",
    "| id | integer |  \n",
    "| username | character |  \n",
    "| email | character |  \n",
    "| city | character |  \n",
    "| state | character |  \n",
    "| zip | integer |  \n",
    "| active | boolean |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### construct a query to find the top 5 states with the highest number of active users. Include the number for each state in the query result. Example result:  \n",
    "| state | num_active_users |  \n",
    "|---|---|  \n",
    "| New Mexico | 502 |  \n",
    "| Alabama | 495 |  \n",
    "| California | 300 |  \n",
    "| Maine | 201 |  \n",
    "| Texas | 189 |   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_actives(data):\n",
    "    s1 = data.groupby('state').size() # count by each state\n",
    "    s2 = s1.sort_values(axis=0, ascending=False) # sort by count\n",
    "    s3 = pd.Series(s2, name='num_active_users') # add key name for count value \n",
    "    return s3.reset_index() # convert series to dataframe\n",
    "\n",
    "top_actives(users).head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Define a function first_unique that takes a string as input and returns the first non-repeated (unique) character in the input string. If there are no unique characters return None. Note: Your code should be in Python.\n",
    "  \n",
    "def first_unique(string):  \n",
    "*** Your code here ***  \n",
    " return unique_char\n",
    "\n",
    "> first_unique('aabbcdd123')\n",
    "> c\n",
    "\n",
    "> first_unique('a')\n",
    "> a\n",
    "\n",
    "> first_unique('112233')\n",
    "> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "a\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def first_unique(string):\n",
    "    Uniq = set(string)\n",
    "    hasUniq = False\n",
    "    for s in Uniq:\n",
    "        if string.count(s)==1 and s.isdigit()==False:\n",
    "            print s\n",
    "            hasUniq = True\n",
    "    if hasUniq == False:\n",
    "        print 'None'\n",
    "\n",
    "first_unique('aabbcdd123')\n",
    "first_unique('a')\n",
    "first_unique('112233')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - What are underfitting and overfitting in the context of Machine Learning? How might you balance them?\n",
    "*** Underfitting *** is a model that can neither training data not generalize to new data. It is not easy to detect given a good performance metric. The remedy is to move on and try alternate machine learning algorithms, but it does provide a good contrast to the problem of the concept of overfitting.  \n",
    "*** Overfitting *** is a model training data too well. The model will learn the detail and noise in the training data, this means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model, but the problem is that these concepts do not apply to new data.  \n",
    "*** Ideally, you want to select a model at the sweet spot between underfitting and overfitting. ***\n",
    "Both overfitting and underfitting can lead to poor model performance. But by far the most common problem in applied machine learning is overfitting.  \n",
    "There are two important techniques to limit overfitting:  \n",
    "1 - Use a resampling technique to estimate model accuracy.  \n",
    "2 - Hold back a validation dataset.  \n",
    "k-fold cross validation. It allows you to train and test your model k-times on different subsets of training data and build up an estimate of the performance of a machine learning model on unseen data.  \n",
    "Using cross-validation is a gold standard in applied machine learning for estimating model accuracy on unseen data. If you have the data, using a validation dataset is also an excellent practice.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - If you were to start your data analyst position today, what would be your goals a year from now?\n",
    "My goal is to become technically sufficient in R, Python and SQL, meet requirements as a Data Analyst.  \n",
    "(First 3 months)  \n",
    "1 - Understand every single table in the database.  \n",
    "2 - Ability to do fundamental data analysis (data visulization, statistical inference, etc.)  \n",
    "(Within one year)  \n",
    "3 - Code fluently in Python to develop new innovative metrics.  \n",
    "4 - Query database and create a hypothesis and test it. If this hypothesis is true, I will target those new emerging segment.  \n",
    "5 - Develop new data product. Such as using machine learning to analyze and predict data and make a recommendation to customers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
